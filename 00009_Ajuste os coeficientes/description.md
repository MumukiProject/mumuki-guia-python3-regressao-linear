Ahora que validamos grÃ¡fica y numÃ©ricamente que la correlaciÃ³n es significativa (aunque no muy fuerte, tan sÃ³lo â‰ˆ `0.6`), podemos finalmente desarrollar (o como se suele decir frecuentemente, _ajustar_) nuestro modelo de regresiÃ³n lineal simple. :raised_hands:  

ğŸ’º Ajustar al modelo consiste en estimar, a partir de los datos disponibles:

 - la recta que minimice la distancia `Îµ` entre las observaciones de `x` y Ã©sta;
 - encontrar los valores de los coeficientes de regresiÃ³n que maximizan la probabilidad de que la recta prediga los valores observados.

El mÃ©todo  mÃ¡s utilizado para Ã©sto es el de mÃ­nimos cuadrados ordinarios (o _OLS_, por sus siglas en inglÃ©s) y `scikit-learn` lo implementa mediante `LinearRegression()`:

```python
X = diabetes[['body_mass_index']]
y = diabetes['response']

modelo = LinearRegression()
modelo.fit(X = X.values, y = y)
```

Como vemos, primero debemos crear un `modelo` y seguidamente ajustarlo utilizando su operaciÃ³n `fit`, indicando los valores de `X` e `y`.  Luego podremos imprimir los valores encontrados de ordenada al origen (`intercept_`) y la pendiente (el primer valor del vector `coef_`):

```python
print("Ordenada:", modelo.intercept_)
print("Pendiente:", list(zip(X.columns, modelo.coef_.flatten())))
```

> CopiÃ¡ y ejecutÃ¡ el cÃ³digo anterior y respondÃ©. Â¿CuÃ¡l de las ecuaciones **representa mejor** al modelo obtenido?