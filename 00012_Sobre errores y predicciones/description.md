Como mencionamos anteriormente, el m√©todo m√°s utilizado para el ajuste del modelo lineal es el de m√≠nimos cuadrados ordinarios (_OLS_), que identifica como mejor modelo la recta (o plano si es regresi√≥n m√∫ltiple) que minimiza la suma de los cuadrados de los errores...

<pre>
<code>Œµ<sup>2</sup> = ‚àë (yi - ≈∑i)<sup>2</sup></code>
</pre>

...donde <code>y<sub>i</sub></code> son los valores observados e <code>≈∑<sub>i</sub></code>, los valores estimados. 

Pero esta f√≥rmula tiene una doble utilidad, porque podemos partir de ella para generar otro par√°metro de la bondad del modelo üòá: la ra√≠z del error cuadr√°tico medio (_RMSE_, por sus siglas en ingl√©s). RMSE mide justamente la ra√≠z cuadrada del error (<code>‚àë (yi - ≈∑i)<sup>2</sup></code>), promediado. Nuevamente `scikit-learn` nos provee una funci√≥n `mean_squared_error` para asistirnos con este c√°lculo:

```python
y_pred = modelo.predict(X = X_test)

rmse = mean_squared_error(
  y_true  = y_test,
  y_pred  = y_pred,
  squared = False
)

print("RMSE:", rmse)
```

> Ahora te toca a vos: gener√° una nueva partici√≥n `train / test` de `75% / 25%` y `random_state = 42` y detall√° los par√°metros obtenidos.  