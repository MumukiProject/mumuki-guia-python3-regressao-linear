Como mencionamos anteriormente, o m√©todo mais utilizado para o ajuste do modelo linear √© o dos m√≠nimos quadrados ordin√°rios (_OLS_), que identifica como melhor modelo a reta (ou plano se for regress√£o m√∫ltipla) que minimiza a soma dos quadrados dos erros...

<pre>
<code>Œµ<sup>2</sup> = ‚àë (yi - ≈∑i)<sup>2</sup></code>
</pre >

...onde <code>y<sub>i</sub></code> s√£o os valores observados e <code>≈∑<sub>i</sub></code> os valores estimados.

Mas essa f√≥rmula tem dupla utilidade, pois podemos partir dela para gerar outro par√¢metro da bondade do modelo üòá: a raiz do erro quadr√°tico m√©dio (_RMSE_, por sua sigla em ingl√™s). O RMSE mede apenas a raiz quadrada do erro (<code>‚àë (yi - ≈∑i)<sup>2</sup></code>), em m√©dia. Novamente `scikit-learn` nos fornece uma fun√ß√£o `mean_squared_error` para nos ajudar com este c√°lculo:

```python
y_pred = modelo.predict(X = X_test)

rmse = mean_squared_error(
  y_true = y_test,
  y_pred = y_pred,
  squared = False
)

print("RMSE:", rmse)
```
> Agora √© sua vez: gere uma nova parti√ß√£o `train / test` de `75% / 25%` e `random_state = 42` e liste os par√¢metros obtidos. 
